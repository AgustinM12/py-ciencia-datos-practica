{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0d1d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'action', 1: 'adventure', 2: 'crime', 3: 'family', 4: 'fantasy', 5: 'horror', 6: 'mystery', 7: 'romance', 8: 'scifi', 9: 'thriller'}\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IPF-2025\\Desktop\\MATERIALES\\py-ciencia-datos-practica\\keras-env\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1122 - loss: 2.2969 - val_accuracy: 0.2107 - val_loss: 2.1439\n",
      "Epoch 2/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2545 - loss: 2.0436 - val_accuracy: 0.2685 - val_loss: 1.9567\n",
      "Epoch 3/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3230 - loss: 1.8670 - val_accuracy: 0.2886 - val_loss: 1.9569\n",
      "Epoch 4/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3531 - loss: 1.7910 - val_accuracy: 0.3306 - val_loss: 1.8611\n",
      "Epoch 5/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3751 - loss: 1.7424 - val_accuracy: 0.3269 - val_loss: 1.8751\n",
      "Epoch 6/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3930 - loss: 1.6987 - val_accuracy: 0.3384 - val_loss: 1.8637\n",
      "Epoch 7/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3956 - loss: 1.6790 - val_accuracy: 0.3450 - val_loss: 1.8347\n",
      "Epoch 8/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4157 - loss: 1.6345 - val_accuracy: 0.3489 - val_loss: 1.8349\n",
      "Epoch 9/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4269 - loss: 1.6108 - val_accuracy: 0.3448 - val_loss: 1.8576\n",
      "Epoch 10/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4439 - loss: 1.5723 - val_accuracy: 0.3321 - val_loss: 1.8652\n",
      "Epoch 11/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4430 - loss: 1.5523 - val_accuracy: 0.3481 - val_loss: 1.8621\n",
      "Epoch 12/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4596 - loss: 1.5271 - val_accuracy: 0.3279 - val_loss: 1.9366\n",
      "Epoch 13/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4661 - loss: 1.5069 - val_accuracy: 0.3345 - val_loss: 1.8991\n",
      "Epoch 14/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4719 - loss: 1.4807 - val_accuracy: 0.3331 - val_loss: 1.9414\n",
      "Epoch 15/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4805 - loss: 1.4520 - val_accuracy: 0.3366 - val_loss: 1.9283\n",
      "Epoch 16/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4854 - loss: 1.4380 - val_accuracy: 0.3315 - val_loss: 1.9217\n",
      "Epoch 17/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4892 - loss: 1.4250 - val_accuracy: 0.3246 - val_loss: 1.9992\n",
      "Epoch 18/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4961 - loss: 1.4016 - val_accuracy: 0.3208 - val_loss: 1.9622\n",
      "Epoch 19/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5022 - loss: 1.3838 - val_accuracy: 0.3184 - val_loss: 2.0643\n",
      "Epoch 20/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5099 - loss: 1.3631 - val_accuracy: 0.3070 - val_loss: 2.0716\n",
      "Epoch 21/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5195 - loss: 1.3470 - val_accuracy: 0.3131 - val_loss: 2.0581\n",
      "Epoch 22/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5185 - loss: 1.3384 - val_accuracy: 0.3211 - val_loss: 2.1021\n",
      "Epoch 23/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5210 - loss: 1.3261 - val_accuracy: 0.2983 - val_loss: 2.1288\n",
      "Epoch 24/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5259 - loss: 1.3123 - val_accuracy: 0.3068 - val_loss: 2.1168\n",
      "Epoch 25/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5268 - loss: 1.2905 - val_accuracy: 0.3069 - val_loss: 2.1711\n",
      "Epoch 26/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5306 - loss: 1.2898 - val_accuracy: 0.3187 - val_loss: 2.1714\n",
      "Epoch 27/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5398 - loss: 1.2667 - val_accuracy: 0.3092 - val_loss: 2.1642\n",
      "Epoch 28/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5435 - loss: 1.2581 - val_accuracy: 0.2905 - val_loss: 2.1885\n",
      "Epoch 29/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5418 - loss: 1.2485 - val_accuracy: 0.2959 - val_loss: 2.3225\n",
      "Epoch 30/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5481 - loss: 1.2379 - val_accuracy: 0.2959 - val_loss: 2.2136\n",
      "Epoch 31/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5502 - loss: 1.2268 - val_accuracy: 0.3049 - val_loss: 2.3578\n",
      "Epoch 32/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5549 - loss: 1.2139 - val_accuracy: 0.2945 - val_loss: 2.3230\n",
      "Epoch 33/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5515 - loss: 1.2164 - val_accuracy: 0.2930 - val_loss: 2.3710\n",
      "Epoch 34/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5633 - loss: 1.1882 - val_accuracy: 0.2903 - val_loss: 2.3432\n",
      "Epoch 35/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5646 - loss: 1.1873 - val_accuracy: 0.2869 - val_loss: 2.3698\n",
      "Epoch 36/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5719 - loss: 1.1671 - val_accuracy: 0.2840 - val_loss: 2.4241\n",
      "Epoch 37/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5730 - loss: 1.1547 - val_accuracy: 0.2916 - val_loss: 2.5295\n",
      "Epoch 38/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5738 - loss: 1.1496 - val_accuracy: 0.2573 - val_loss: 2.4944\n",
      "Epoch 39/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5794 - loss: 1.1350 - val_accuracy: 0.2759 - val_loss: 2.4835\n",
      "Epoch 40/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5795 - loss: 1.1271 - val_accuracy: 0.2844 - val_loss: 2.4904\n",
      "Epoch 41/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5809 - loss: 1.1157 - val_accuracy: 0.2659 - val_loss: 2.5328\n",
      "Epoch 42/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5871 - loss: 1.1055 - val_accuracy: 0.2962 - val_loss: 2.6611\n",
      "Epoch 43/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5939 - loss: 1.0912 - val_accuracy: 0.2803 - val_loss: 2.5791\n",
      "Epoch 44/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5953 - loss: 1.0812 - val_accuracy: 0.2772 - val_loss: 2.6534\n",
      "Epoch 45/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6019 - loss: 1.0674 - val_accuracy: 0.2720 - val_loss: 2.6819\n",
      "Epoch 46/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5992 - loss: 1.0688 - val_accuracy: 0.2767 - val_loss: 2.7103\n",
      "Epoch 47/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6123 - loss: 1.0426 - val_accuracy: 0.2823 - val_loss: 2.7474\n",
      "Epoch 48/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 1.0365 - val_accuracy: 0.2750 - val_loss: 2.8538\n",
      "Epoch 49/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6252 - loss: 1.0148 - val_accuracy: 0.2720 - val_loss: 2.8539\n",
      "Epoch 50/50\n",
      "\u001b[1m1350/1350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6204 - loss: 1.0105 - val_accuracy: 0.2785 - val_loss: 2.9144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "prediccion:  [[7.7097314e-07 7.5238148e-08 2.1908366e-09 2.2317365e-11 8.0255115e-05\n",
      "  5.3379107e-01 4.3669978e-01 6.1153543e-14 1.0902799e-05 2.9417166e-02]]\n",
      "horror\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "# * 1. Cargar datos\n",
    "df = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "# * 2. Preprocesar los datos a analizar\n",
    "texts = df[\"synopsis\"].astype(str).values\n",
    "genres = df[\"genre\"].astype(str).values\n",
    "\n",
    "# * Codificar géneros de peliculas\n",
    "unique_genres = sorted(set(genres))\n",
    "genre_to_index = {genre: i for i, genre in enumerate(unique_genres)}\n",
    "index_to_genre = {i: genre for genre, i in genre_to_index.items()}\n",
    "y = np.array([genre_to_index[g] for g in genres])\n",
    "y = to_categorical(y, num_classes=len(unique_genres))\n",
    "\n",
    "print(index_to_genre)\n",
    "print(y)\n",
    "\n",
    "# * Tokenizar texto\n",
    "# ? convierte a las palabras en numeros (especificamente las 5000 mas comunes, el resto se marcan como \"<OOV>\")\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "\n",
    "# ? analiza las palabras y crea un diccionario basado en las frecuencias.\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# ? convierte cada sinopsis en secuencias de numeros.\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# ? normaliza las sequencias con un maximo de 100 tokens (si es mas larga se trunca, sino se rellena de 0s)\n",
    "X = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# ? Separar datos manualmente (80% entrenamiento /20% prueba)\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# * 3. Construir modelo\n",
    "model = Sequential([\n",
    "    # ? convierte los tokens en vectores densos de 64 dimensiones.\n",
    "    Embedding(input_dim=5000, output_dim=64, input_length=100),\n",
    "    # ? Reduce la dimensionalidad promediando los vectores.\n",
    "    GlobalAveragePooling1D(),\n",
    "    # ? Define una capa densa con 64 neuronas\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    # ? Define una capa densa con una neurona por cada genero\n",
    "    Dense(len(unique_genres), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# * Compilacion del modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# * 4. Entrenar el modelo con 10 epocas (pasadas completas de TODOS los datos).\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "# 5. Predicción de ejemplo\n",
    "def predecir_genero(sinopsis):\n",
    "    # ? convierte la sinopsis recibida en una sequencia de tokens\n",
    "    seq = tokenizer.texts_to_sequences([sinopsis])\n",
    "    # ? normaliza los datos al igual que a los de entrenamiento\n",
    "    padded = pad_sequences(seq, maxlen=100)\n",
    "    # ? realiza la prediccion\n",
    "    pred = model.predict(padded)\n",
    "    # ? realiza la prediccion\n",
    "    print(\"prediccion: \", pred)\n",
    "    return index_to_genre[np.argmax(pred)]\n",
    "\n",
    "print(predecir_genero(\"A family moves into an old house where terrifying paranormal phenomena begin to occur. Desperate, they turn to supernatural investigators Ed and Lorraine Warren, who discover that a dark, demonic presence is haunting the place. To save the family, they must confront a malevolent entity that threatens to possess them all.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
